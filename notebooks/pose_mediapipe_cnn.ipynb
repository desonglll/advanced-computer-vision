{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Extract Part",
   "id": "30fe77353875170c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from mediapipe_impl.pose_estimation import PoseEstimationModule as pm\n",
    "\n",
    "# cap = cv2.VideoCapture(0)\n",
    "detector = pm.PoseDetector()\n",
    "\n",
    "images_dir = \"../datasets/img\"\n",
    "images = [os.path.join(images_dir, img) for img in os.listdir(images_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]"
   ],
   "id": "6c4cb1c54556d64b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:29:40.023653Z",
     "start_time": "2024-11-16T12:29:36.274439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tqdm\n",
    "\n",
    "# 读取现有JSON文件（如果存在），将新数据追加到列表中\n",
    "json_file_path = \"../train_data/keypoint_data.json\"\n",
    "# 检查文件是否存在\n",
    "if not os.path.exists(json_file_path):\n",
    "    # 文件不存在时初始化空列表\n",
    "    data_list = []\n",
    "else:\n",
    "    # 文件已存在，跳过读取\n",
    "    data_list = []\n",
    "\n",
    "for image_path in tqdm.tqdm(images):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = detector.find_pose(img, draw=False)\n",
    "    lm_list = detector.find_position(img, False)\n",
    "    data = {\n",
    "        \"filename\": image_path.split('/')[-1],\n",
    "        \"features\": lm_list,\n",
    "    }\n",
    "\n",
    "    # 追加新数据\n",
    "    data_list.append(data)\n",
    "\n",
    "# 将更新后的列表写回JSON文件\n",
    "with open(json_file_path, \"w\") as file:\n",
    "    json.dump(data_list, file, indent=4)\n",
    "\n"
   ],
   "id": "2fadc7c68e69e96a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 26.87it/s]\n"
     ]
    }
   ],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Label Part\n",
    "\n",
    "## Put all.jsonl from doccano to train_data directory"
   ],
   "id": "8313e793ce047f91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Combine Data Part",
   "id": "72bc8863b5e0297d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:04.454568Z",
     "start_time": "2024-11-16T12:30:04.451210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def jsonl_to_json(jsonl_file_path, output_json_file_path):\n",
    "    \"\"\"\n",
    "    将 JSONL 文件中的数据转换为标准的 JSON 格式文件。\n",
    "\n",
    "    :param jsonl_file_path: JSONL 文件路径\n",
    "    :param output_json_file_path: 输出的 JSON 文件路径\n",
    "    \"\"\"\n",
    "    merged_data = []\n",
    "\n",
    "    # 打开 JSONL 文件并逐行处理\n",
    "    with open(jsonl_file_path, 'r') as jsonl_file:\n",
    "        for line in jsonl_file:\n",
    "            item = json.loads(line)  # 解析每一行的 JSON 对象\n",
    "            merged_data.append(item)\n",
    "\n",
    "    # 将合并后的数据写入输出 JSON 文件\n",
    "    with open(output_json_file_path, 'w') as json_file:\n",
    "        json.dump(merged_data, json_file, indent=4)\n",
    "\n",
    "    print(f\"Converted JSONL data saved to {output_json_file_path}\")\n"
   ],
   "id": "465af7df0a7e1c67",
   "outputs": [],
   "execution_count": 115
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:05.178016Z",
     "start_time": "2024-11-16T12:30:05.174371Z"
    }
   },
   "cell_type": "code",
   "source": "jsonl_to_json(\"../train_data/all.jsonl\", \"../train_data/all.json\")",
   "id": "7f0506e0474a202a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted JSONL data saved to ../train_data/all.json\n"
     ]
    }
   ],
   "execution_count": 116
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:05.895462Z",
     "start_time": "2024-11-16T12:30:05.891183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def merge_features_by_filename(file1_path, file2_path, output_path):\n",
    "    # 读取两个文件的内容\n",
    "    with open(file1_path, 'r') as f1:\n",
    "        list1 = json.load(f1)\n",
    "\n",
    "    with open(file2_path, 'r') as f2:\n",
    "        list2 = json.load(f2)\n",
    "\n",
    "    # 创建一个以 filename 为键的字典，便于快速查找\n",
    "    features_dict = {item[\"filename\"]: item[\"features\"] for item in list1}\n",
    "\n",
    "    # 遍历 list2，将 features 合并\n",
    "    for item in list2:\n",
    "        filename = item[\"filename\"]\n",
    "        if filename in features_dict:\n",
    "            item[\"features\"] = features_dict[filename]\n",
    "\n",
    "    # 将合并后的数据写入输出文件\n",
    "    with open(output_path, 'w') as out_file:\n",
    "        json.dump(list2, out_file, indent=4)\n",
    "\n",
    "    print(f\"Merged data saved to {output_path}\")\n"
   ],
   "id": "8cf4843d474d1ddb",
   "outputs": [],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:06.631296Z",
     "start_time": "2024-11-16T12:30:06.599830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "merge_features_by_filename(\"../train_data/keypoint_data.json\", \"../train_data/all.json\",\n",
    "                           \"../train_data/merged_data.json\")"
   ],
   "id": "2e83325e2d22599b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to ../train_data/merged_data.json\n"
     ]
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Model Train Part"
   ],
   "id": "1abd031bcb7a4bb0"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:07.990092Z",
     "start_time": "2024-11-16T12:30:07.987346Z"
    }
   },
   "source": [
    "import json\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 119
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:08.690619Z",
     "start_time": "2024-11-16T12:30:08.685634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_data(json_path):\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    inputs = []\n",
    "    labels = []\n",
    "    for sample in data:\n",
    "        if sample[\"label\"]:\n",
    "            features = sample[\"features\"]\n",
    "            # Flatten each (x, y, z, visibility) into a single array\n",
    "            flattened_features = []\n",
    "            for keypoint in features:\n",
    "                flattened_features.extend([keypoint[\"x\"], keypoint[\"y\"], keypoint[\"z\"], keypoint[\"visibility\"]])\n",
    "\n",
    "            inputs.append(flattened_features)\n",
    "\n",
    "            # Multi-label processing: Convert label list to a binary vector\n",
    "            label_list = sample[\"label\"]\n",
    "            labels.append(label_list)\n",
    "\n",
    "    return np.array(inputs), labels"
   ],
   "id": "f3145b14e537b7e3",
   "outputs": [],
   "execution_count": 120
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:49.508247Z",
     "start_time": "2024-11-16T12:30:49.472171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "print(\"Load Data\")\n",
    "X, y = load_data('../train_data/merged_data.json')\n",
    "print(f\"Labels: {y}\")\n",
    "print(f\"Initial X shape: {X.shape}\")\n",
    "ALL_LABELS = []\n",
    "for label in y:\n",
    "    if label and label not in ALL_LABELS:\n",
    "        ALL_LABELS.append(label)\n",
    "print(f\"ALL LABELS: {ALL_LABELS}\")\n",
    "# N categories\n",
    "N = len(ALL_LABELS)\n",
    "print(f\"N: {N}\")\n",
    "KEY_POINTS = 33\n",
    "FEATURES = 4\n",
    "# Reshape data to fit Conv1D input: (samples, steps, features)\n",
    "X = X.reshape((X.shape[0], KEY_POINTS, 4))  # 33 keypoints with 4 features (x, y, z, visibility)\n",
    "# Checking the shape of the reshaped data\n",
    "print(X.shape)"
   ],
   "id": "f3b415bed9709668",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data\n",
      "Labels: [['Blur'], ['Normal'], ['Blur'], ['Normal'], ['Blur'], ['Blur'], ['Wrong'], ['Blur'], ['Blur'], ['Wrong'], ['Blur'], ['Wrong'], ['Blur'], ['Wrong'], ['Normal'], ['Normal'], ['Normal'], ['Normal'], ['Normal'], ['Normal']]\n",
      "Initial X shape: (20, 132)\n",
      "ALL LABELS: [['Blur'], ['Normal'], ['Wrong']]\n",
      "N: 3\n",
      "(20, 33, 4)\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:52.351569Z",
     "start_time": "2024-11-16T12:30:52.342876Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Initialize a LabelEncoder to convert strings to integers\n",
    "label_encoder = LabelEncoder()\n",
    "# Fit and transform the labels to integers\n",
    "y_int = label_encoder.fit_transform(y)\n",
    "# Now apply to_categorical for one-hot encoding\n",
    "y_onehot = to_categorical(y_int, num_classes=len(label_encoder.classes_))\n",
    "print(f\"One-hot encoded labels shape: {y_onehot.shape}\")\n",
    "print(y_onehot)\n"
   ],
   "id": "6aa37bdd4e1bc198",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot encoded labels shape: (20, 3)\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeshinoda/Library/Caches/pypoetry/virtualenvs/advanced-computer-vision-mRP4g53R-py3.12/lib/python3.12/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:57.145500Z",
     "start_time": "2024-11-16T12:30:57.085183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "# Add Conv1D layer\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(KEY_POINTS, FEATURES)))\n",
    "# Add MaxPooling1D layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# Add another Conv1D layer\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "# Add another MaxPooling1D layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "# Flatten the output from Conv1D layers\n",
    "model.add(Flatten())\n",
    "# Add Dense layer with dropout for regularization\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "# Output layer with softmax activation (for classification)\n",
    "model.add(Dense(N, activation='softmax'))  # N is the number of classes"
   ],
   "id": "eabe977a1ebf87b5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mikeshinoda/Library/Caches/pypoetry/virtualenvs/advanced-computer-vision-mRP4g53R-py3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:30:58.509500Z",
     "start_time": "2024-11-16T12:30:58.488264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Summary of the model\n",
    "model.summary()"
   ],
   "id": "de6af3fb27d91125",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_4 (\u001B[38;5;33mConv1D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m31\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │           \u001B[38;5;34m832\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (\u001B[38;5;33mMaxPooling1D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m15\u001B[0m, \u001B[38;5;34m64\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (\u001B[38;5;33mConv1D\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m13\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │        \u001B[38;5;34m24,704\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (\u001B[38;5;33mMaxPooling1D\u001B[0m)  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6\u001B[0m, \u001B[38;5;34m128\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m768\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │        \u001B[38;5;34m98,432\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3\u001B[0m)              │           \u001B[38;5;34m387\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,432</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m124,355\u001B[0m (485.76 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,355</span> (485.76 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m124,355\u001B[0m (485.76 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">124,355</span> (485.76 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 127
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:31:00.404965Z",
     "start_time": "2024-11-16T12:30:59.492695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train the Model\n",
    "history = model.fit(X, y_onehot, epochs=10, batch_size=32, validation_split=0.2)\n",
    "# Evaluate the Model\n",
    "loss, accuracy = model.evaluate(X, y_onehot)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ],
   "id": "c39b501a12ba927a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 570ms/step - accuracy: 0.2500 - loss: 1.1556 - val_accuracy: 0.0000e+00 - val_loss: 1.4210\n",
      "Epoch 2/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5000 - loss: 1.1388 - val_accuracy: 0.0000e+00 - val_loss: 1.6627\n",
      "Epoch 3/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - accuracy: 0.5000 - loss: 1.0761 - val_accuracy: 0.0000e+00 - val_loss: 1.7260\n",
      "Epoch 4/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5000 - loss: 1.0059 - val_accuracy: 0.0000e+00 - val_loss: 1.6852\n",
      "Epoch 5/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - accuracy: 0.5000 - loss: 1.0579 - val_accuracy: 0.0000e+00 - val_loss: 1.6454\n",
      "Epoch 6/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step - accuracy: 0.5000 - loss: 1.0794 - val_accuracy: 0.0000e+00 - val_loss: 1.5937\n",
      "Epoch 7/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5000 - loss: 0.9749 - val_accuracy: 0.0000e+00 - val_loss: 1.5462\n",
      "Epoch 8/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - accuracy: 0.5000 - loss: 1.1168 - val_accuracy: 0.0000e+00 - val_loss: 1.4667\n",
      "Epoch 9/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5000 - loss: 1.0380 - val_accuracy: 0.0000e+00 - val_loss: 1.3840\n",
      "Epoch 10/10\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - accuracy: 0.5000 - loss: 1.0648 - val_accuracy: 0.0000e+00 - val_loss: 1.3371\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 12ms/step - accuracy: 0.4000 - loss: 1.0994\n",
      "Accuracy: 40.00%\n"
     ]
    }
   ],
   "execution_count": 128
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:31:01.512804Z",
     "start_time": "2024-11-16T12:31:01.502331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "from mediapipe_impl.pose_estimation import PoseEstimationModule as pm\n",
    "\n",
    "detector = pm.PoseDetector()\n",
    "\n",
    "\n",
    "def extract_keypoints(image_path):\n",
    "    cap = cv2.VideoCapture(image_path)\n",
    "    success, img = cap.read()\n",
    "    img = detector.find_pose(img=img)\n",
    "    lm_list = detector.find_position(img, draw=False)\n",
    "    return lm_list"
   ],
   "id": "7918daa27179925b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1731760261.509316 5614427 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M1\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-16T12:31:03.378677Z",
     "start_time": "2024-11-16T12:31:03.247496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_image(image_path):\n",
    "    data = []\n",
    "    keypoints = extract_keypoints(image_path)\n",
    "    for keypoint in keypoints:\n",
    "        data.extend([keypoint[\"x\"], keypoint[\"y\"], keypoint[\"z\"], keypoint[\"visibility\"]])\n",
    "    X = np.array(data).reshape((1, 33, 4))\n",
    "    print(X.shape)\n",
    "    # 模型预测\n",
    "    predictions = model.predict(X)\n",
    "\n",
    "    # 获取预测类别的索引\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    print(ALL_LABELS[predicted_class])\n",
    "\n",
    "\n",
    "# 示例：预测一张新图像\n",
    "image_path = '../datasets/img.jpg'\n",
    "result = predict_image(image_path)"
   ],
   "id": "a9b9c16f7d945f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 33, 4)\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "Predicted Class: 0\n",
      "['Blur']\n"
     ]
    }
   ],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b843624e1e98a5dc",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
